{
 "cells": [
  {
   "cell_type": "code",
   "id": "6e41eb911c1681a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:33:29.691698Z",
     "start_time": "2026-01-24T18:33:10.944364Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ViTGSOM import AutoEncoder, ViTSOMLoss\n",
    "from help_functions import get_grid_coords, decay_exponential, calculate_purity, plot_umap_som_weights, get_node_labels"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "80bd43da76dead1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:33:29.735962Z",
     "start_time": "2026-01-24T18:33:29.695634Z"
    }
   },
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ce4661b78ae81721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:33:29.990163Z",
     "start_time": "2026-01-24T18:33:29.985424Z"
    }
   },
   "source": [
    "config = {\n",
    "    'img_size': 28,\n",
    "    'patch_size': 4,\n",
    "    'num_of_channels': 1,\n",
    "    'embed_dim': 16,\n",
    "    'enc_depth': 4,\n",
    "    'dec_depth': 2,\n",
    "    'num_heads': 2,\n",
    "    'mlp_dim': 64,\n",
    "    'epochs': 400,\n",
    "    'lr': 0.0005,\n",
    "    'grow_after_epochs': 10,\n",
    "    'grow_threshold': 0.5,\n",
    "    'spread_factor': 0.5,\n",
    "    'som_rows': 5,\n",
    "    'som_cols': 5\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ea726cd44a3a93e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:33:30.015985Z",
     "start_time": "2026-01-24T18:33:29.998788Z"
    }
   },
   "source": [
    "autoencoder = AutoEncoder(img_size=config['img_size'], \n",
    "                          patch_size=config['patch_size'], \n",
    "                          num_of_channels=config['num_of_channels'], \n",
    "                          embed_dim=config['embed_dim'], \n",
    "                          enc_depth=config['enc_depth'],                                      \n",
    "                          dec_depth=config['dec_depth'], \n",
    "                          num_heads=config['num_heads'], \n",
    "                          mlp_dim=config['mlp_dim'],\n",
    "                          spread_factor=config['spread_factor'],\n",
    "                          som_rows=config['som_rows'],\n",
    "                          som_cols=config['som_cols'])    "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:35:57.984606Z",
     "start_time": "2026-01-24T18:33:30.023994Z"
    }
   },
   "source": [
    "optimizer = optim.AdamW(autoencoder.parameters(), lr=config['lr'])\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "criterion = ViTSOMLoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder.to(device)\n",
    "autoencoder.train()\n",
    "\n",
    "# starting and ending value of sigma, beta is calculated to reach sigma_end at last epoch\n",
    "sigma_start = autoencoder.get_sigma()\n",
    "sigma_end = 0.5\n",
    "beta = (sigma_end / sigma_start) ** (1 / config['grow_after_epochs'])\n",
    "\n",
    "grid_coords = get_grid_coords(config['som_rows'], config['som_cols'], device)\n",
    "current_sigma = sigma_start\n",
    "\n",
    "history = {'total': [], 'mse': [], 'som': [], 'purity': []}\n",
    "\n",
    "checkpoints = [0,10,25,50,100,150,200]\n",
    "snapshot_som_weights = {}\n",
    "snapshot_som_weights[0] = (\n",
    "    autoencoder.get_som_weights().detach().cpu().numpy(),\n",
    "    get_node_labels(autoencoder, loader, device)\n",
    ")\n",
    "\n",
    "print(\"Start training\")\n",
    "for epoch in range(config['epochs']):\n",
    "    running_loss = 0.0\n",
    "    running_mse = 0.0\n",
    "    running_som = 0.0\n",
    "    current_lambda = 1 \n",
    "    \n",
    "    sigma_t = decay_exponential(sigma_start, beta, epoch)\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        reconstructed, latent = autoencoder(images)\n",
    "        som_weights = autoencoder.get_som_weights()\n",
    "        \n",
    "        total_loss, l_nn, l_som = criterion(images, reconstructed, latent, som_weights, grid_coords, sigma_t, current_lambda)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "        running_mse += l_nn.item()\n",
    "        running_som += l_som.item()\n",
    "    \n",
    "    if epoch+1 in checkpoints:        \n",
    "        weights_np = autoencoder.get_som_weights().detach().cpu().numpy()\n",
    "        labels_np = get_node_labels(autoencoder, loader, device)\n",
    "        snapshot_som_weights[epoch+1] = (weights_np, labels_np)\n",
    "        \n",
    "    if (epoch+1) % config['grow_after_epochs'] == 0:\n",
    "        if autoencoder.check_growth(loader, device):\n",
    "            optimizer = optim.AdamW(autoencoder.parameters(), lr=config['lr'])\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'], last_epoch=epoch)\n",
    "            grid_coords = get_grid_coords(autoencoder.current_row_num, autoencoder.current_col_num, device)\n",
    "    \n",
    "    # updating learning rule through CosineAnnealingLR\n",
    "    scheduler.step()\n",
    "    purity = calculate_purity(autoencoder, loader, device)\n",
    "    \n",
    "    avg_total = running_loss / len(loader)\n",
    "    avg_mse = running_mse / len(loader)\n",
    "    avg_som = running_som / len(loader)\n",
    "    \n",
    "    history['total'].append(avg_total)\n",
    "    history['mse'].append(avg_mse)\n",
    "    history['som'].append(avg_som)\n",
    "    history['purity'].append(purity)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config['epochs']} | Sigma: {sigma_t:.2f} | Loss: {avg_total:.8f} (MSE: {avg_mse:.8f} | SOM: {avg_som:.8f}) | Purity: {purity:.5f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m images, _ \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[32m     37\u001B[39m     images = images.to(device)\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m     reconstructed, latent = \u001B[43mautoencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m     som_weights = autoencoder.get_som_weights()\n\u001B[32m     42\u001B[39m     total_loss, l_nn, l_som = criterion(images, reconstructed, latent, som_weights, grid_coords, sigma_t, current_lambda)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\ViT-GSOM\\ViTGSOM.py:243\u001B[39m, in \u001B[36mAutoEncoder.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     latent = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    244\u001B[39m     patched_output = \u001B[38;5;28mself\u001B[39m.decoder(latent)\n\u001B[32m    245\u001B[39m     output = unpatch(patched_output, \u001B[38;5;28mself\u001B[39m.patch_size, \u001B[38;5;28mself\u001B[39m.num_of_channels)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\ViT-GSOM\\ViTGSOM.py:179\u001B[39m, in \u001B[36mViTEncoder.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;66;03m# apply self attention layers and mlp\u001B[39;00m\n\u001B[32m    178\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.blocks:\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m     x = \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    181\u001B[39m x = \u001B[38;5;28mself\u001B[39m.ln1(x)\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\ViT-GSOM\\ViTGSOM.py:136\u001B[39m, in \u001B[36mBlock.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m    135\u001B[39m     \u001B[38;5;66;03m# Self-attention\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m     attention_output, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mln1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mln1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mln1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    137\u001B[39m     \u001B[38;5;66;03m# Skip connection\u001B[39;00m\n\u001B[32m    138\u001B[39m     x = x + attention_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1459\u001B[39m, in \u001B[36mMultiheadAttention.forward\u001B[39m\u001B[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001B[39m\n\u001B[32m   1457\u001B[39m             value = key\n\u001B[32m   1458\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1459\u001B[39m         query, key, value = (x.transpose(\u001B[32m1\u001B[39m, \u001B[32m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (query, key, value))\n\u001B[32m   1461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._qkv_same_embed_dim:\n\u001B[32m   1462\u001B[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001B[32m   1463\u001B[39m         query,\n\u001B[32m   1464\u001B[39m         key,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1485\u001B[39m         is_causal=is_causal,\n\u001B[32m   1486\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\tom\\moje\\ViT-GHSOM\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1459\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m   1457\u001B[39m             value = key\n\u001B[32m   1458\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1459\u001B[39m         query, key, value = (\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (query, key, value))\n\u001B[32m   1461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._qkv_same_embed_dim:\n\u001B[32m   1462\u001B[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001B[32m   1463\u001B[39m         query,\n\u001B[32m   1464\u001B[39m         key,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1485\u001B[39m         is_causal=is_causal,\n\u001B[32m   1486\u001B[39m     )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_umap_som_weights(snapshot_som_weights)",
   "id": "bdc9c4891e9a90c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
